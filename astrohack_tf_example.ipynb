{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AstroHack - Tensorflow + Keras Example\n",
    "\n",
    "This tutorial will demonstrate how to predict galaxy M/L ratios using a simple convolutional neural network with the Keras API of TensorFlow 2.0.\n",
    "\n",
    "1. [Setup](#1.-Setup)    \n",
    "    1.1. [Download data](#1.1.-Download-data)    \n",
    "    1.2. [Install dependencies](#1.2.-Install-dependencies)\n",
    "    \n",
    "2. [Prepare data](#2.-Prepare-data)    \n",
    "    2.1. [Load labels and metadata](#2.1.-Load-labels-and-metadata)    \n",
    "    2.2. [Load images into np.arrays](#2.2.-Load-images-into-numpy-arrays)    \n",
    "    2.3. [Split validation set from training set](#2.3.-Split-validation-set-from-training-set)    \n",
    "3. [Build a simple convolutional neural network](#3.-Build-a-simple-convolutional-neural-network)\n",
    "4. [Generate predictions](#4.-Generate-predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AstroHack data files do not come along with this repository, you need to download them into the `./data` directory before running this notebook.\n",
    "\n",
    "#### If you prefer to download them manually:\n",
    "\n",
    "Please follow the instructions of `./data/README.md` to setup the data folder.\n",
    "\n",
    "\n",
    "#### If you're running this notebook from a AWS SageMaker notebook:\n",
    "\n",
    "1. Identify the S3 bucket name from the links to data files.     \n",
    "   For example, the bolded part in the URI \"__astrohack-public-data__.s3.amazonaws.com/train_metadata.tsv\" is the bucket name.\n",
    "   \n",
    "2. Replace the `<bucket_name>` placeholder in the next cell with the actual bucket name.\n",
    "3. Run the next cell to download and unpack data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running from a SageMaker notebook instance\n",
    "# Update the <bucket_name> placeholder below before execution!\n",
    "!aws s3 cp s3://<bucket_name>/ ./data --recursive\n",
    "    \n",
    "!unzip -q ./data/eval_images_69pix.zip -d ./data\n",
    "!unzip -q ./data/train_images_69pix.zip -d ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Install dependencies\n",
    "\n",
    "Run the following command to install Python dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data\n",
    "\n",
    "We need to load and parse the data files before we can run any machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load labels and metadata\n",
    "\n",
    "Pandas is handy for parsing tabular data and we will use it to load the metadata files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read metadata TSV files\n",
    "train_labels = pd.read_csv('./data/train_metadata.tsv', sep='\\t')\n",
    "eval_labels = pd.read_csv('./data/eval_metadata.tsv', sep='\\t')\n",
    "\n",
    "# Print the shape\n",
    "print('Training metadata shape: {}'.format(train_labels.shape))\n",
    "print('Evaluation metadata shape: {}'.format(eval_labels.shape))\n",
    "\n",
    "# Show head of training metadata\n",
    "train_labels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown above are the top 3 rows in the training metadata files with columns:\n",
    "\n",
    "- `SDSS_ID`: the unique identifier for each galaxy used by SDSS database.\n",
    "- `M/L`: the ground truth Mass-to-Luminosity ratio.\n",
    "- `L_g`: luminosity of the galaxy in g-band wavelength. *Not used in this tutorial.*\n",
    "- `distance_Mpc`: the distance between the subject galaxy and Earth in megaparsec. *Not used in this tutorial.*\n",
    "- `galsize_kpc`: the size of the subject galaxy in kiloparsec. *Not used in this tutorial.*\n",
    "- `image_name`: the filename of the corresponding image file.\n",
    "\n",
    "In this tutorial, we will use the image as the only feature to predict the M/L ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Load images into numpy arrays\n",
    "\n",
    "In this tutorial, we will only use the 69x69pix galatic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate training and evaluation images\n",
    "train_img_folder = './data/train_images_69pix'\n",
    "eval_img_folder = './data/evaluation_images_69pix'\n",
    "\n",
    "print('Found {} training images'.format(len(os.listdir(train_img_folder))))\n",
    "print('Found {} evaluation images'.format(len(os.listdir(eval_img_folder))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load train and eval images into numpy arrays\n",
    "train_image_paths = [train_img_folder + '/' + img_name for img_name in train_labels['image_name']]\n",
    "eval_image_paths = [eval_img_folder + '/' + img_name for img_name in eval_labels['image_name']]\n",
    "\n",
    "train_images = np.array([np.array(Image.open(img_path)) for img_path in train_image_paths])\n",
    "eval_images = np.array([np.array(Image.open(img_path)) for img_path in eval_image_paths])\n",
    "\n",
    "# Expand the channel dimension\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "eval_images = np.expand_dims(eval_images, axis=3)\n",
    "\n",
    "# Show shape\n",
    "print('Training image array shape: {}'.format(train_images.shape))\n",
    "print('Evaluation image array shape: {}'.format(eval_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preview some of the images\n",
    "_show_n_images = 4\n",
    "fig, axs = plt.subplots(ncols=_show_n_images, figsize=(3 * _show_n_images, 3))\n",
    "for i in range(_show_n_images):\n",
    "    axs[i].imshow(train_images[i, :, :, 0], cmap='gray')\n",
    "    axs[i].set_title('{}\\nM/L = {:.4f}'.format(train_labels['SDSS_ID'].iloc[i], \n",
    "                                               train_labels['M/L'].iloc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is 69x69 pix large and there is only one channel (black-and-white), therefore each image can be represented by a tensor with size of (69, 69, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Split validation set from training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically we can use the entire training dataset to train our machine learning model, but practically we need to reserve a small portion of it to validate our model and check the model performance. This reserved portion is often referred as the *validation set*. \n",
    "\n",
    "In this tutorial, we will use 10% of the training data as the validation set, and use the remaining 90% to actually train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.1  # Use 10% of training data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # seed randomness\n",
    "\n",
    "# Move 10% of data into validation set\n",
    "val_index = train_labels.sample(frac=validation_split).index\n",
    "val_labels = train_labels.loc[val_index, :]\n",
    "train_labels = train_labels.loc[~train_labels.index.isin(val_index), :]\n",
    "\n",
    "# Print the shape\n",
    "print('Training metadata shape: {}'.format(train_labels.shape))\n",
    "print('Validation metadata shape: {}'.format(val_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have splitted the training and validation sets, we simply need to lookup the corresponding images and M/L values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_images[train_labels.index.values, :, :]\n",
    "X_val = train_images[val_index.values, :, :]\n",
    "Y_train = train_labels['M/L'].values\n",
    "Y_val = val_labels['M/L'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build a simple convolutional neural network\n",
    "\n",
    "[Convolutional Neural Network (CNN)](https://en.wikipedia.org/wiki/Convolutional_neural_network) is a family of deep learning models that work well on image data. \n",
    "\n",
    "In the below code segments, we will build a simple CNN sturtcure, train it and use it to predict the M/L ratio from galaxy images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Build a simple sequential CNN model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add a batch normalization layer\n",
    "model.add(layers.BatchNormalization(input_shape=(69, 69, 1)))\n",
    "\n",
    "# CNN layer 1\n",
    "model.add(layers.Conv2D(32, kernel_size=5, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.2))  # Dropout is a common technique to prevent overfitting\n",
    "\n",
    "# CNN layer 2\n",
    "model.add(layers.Conv2D(64, kernel_size=3, strides=(1, 1), activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Dense layers to collect the convolutional features and make a single output\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "# Use MSE as the loss function\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val),\n",
    "                    epochs=25, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training curve\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='training_loss')\n",
    "plt.plot(history_df['val_loss'], label='validation_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the training plot, the loss is gradually reduced with more iterations, which indicates the model is learning and making progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate predictions\n",
    "\n",
    "Now our CNN model is trained, we can use it to predict on images in the evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the evaluation set\n",
    "predicted_ml = model.predict(eval_images)\n",
    "\n",
    "# Compile predictions into the submission format\n",
    "eval_labels.loc[:, 'pred_ml'] = predicted_ml\n",
    "eval_submission = eval_labels.loc[:, ['SDSS_ID', 'pred_ml']]\n",
    "eval_submission.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the submission file\n",
    "eval_submission.to_csv('./eval_submission.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can submit this file for evaluation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
